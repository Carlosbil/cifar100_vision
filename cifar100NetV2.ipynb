{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c98ee40",
   "metadata": {},
   "source": [
    "## CIFAR 100 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79f88b",
   "metadata": {},
   "source": [
    "# Stage 1: Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0012c6",
   "metadata": {},
   "source": [
    "In this case we are going to develop a cifar 100 classification problem, for that we a re going to use the cifar100 dataset availablwe in torchvision, Although we are going to apply data augmentation for make the neuronal network more robust, and batch size of 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79018184",
   "metadata": {},
   "source": [
    "For this time i will use 32x32 size images, as it is the cifar100 size images, so all the images will be resized to 32 x 32. alltought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12eb5f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch,os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, ConcatDataset, DataLoader\n",
    "\n",
    "#Augmentation data for being morerobust\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),  # Converts the image into a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((32,32)),  # Resizes the image to 32x32\n",
    "    transforms.ToTensor(),  # Converts the image into a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizes the tensors (mean and std deviation for 3 color channels)\n",
    "])\n",
    "\n",
    "# Create Train dataset\n",
    "train_dataset = datasets.CIFAR100(root = './dataset/train',download=True, train=True, transform=transform_train)\n",
    "# Create Test dataset\n",
    "test_dataset = datasets.CIFAR100(root = './dataset/test',download=True, train=False, transform=transform_test) \n",
    "\n",
    "#Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "#Create test loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34ae2f",
   "metadata": {},
   "source": [
    "# Stage 2: building neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8a8b6",
   "metadata": {},
   "source": [
    "Stride: The stride refers to how many pixels the filter moves through the image or input volume at each step during the convolution operation. A stride of 1 means that the filter moves one pixel at a time. A stride of 2 means that the filter moves two pixels at a time, and so on. A larger stride will result in a lower spatial dimension output.\n",
    "\n",
    "Padding: Padding refers to the addition of extra pixels around the input image or volume before applying the convolution operation. The purpose of padding is to control the spatial dimension of the output. It is especially useful when you want to keep the spatial dimensions of the input and output the same after the convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8baf2e",
   "metadata": {},
   "source": [
    "For this time i will use 4 convolutional layer, letting to the network learn more complex forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f8825",
   "metadata": {},
   "source": [
    "You start with 32x32 images.\n",
    "\n",
    "Each time you apply a pooling layer with a kernel size of 2 and a stride of 2, you halve the height and width dimensions of the image. Since you have 4 pooling layers, the image dimension is reduced to 32 / (2^4) = 2 (rounding down if necessary).\n",
    "\n",
    "The last convolutional layer has 256 output channels. Therefore, the output of the last convolutional layer is a tensor of dimension [256, 2, 2].\n",
    "\n",
    "When you flatten this tensor to feed the fully connected layer, you get a vector of length 256 * 2 * 2 = 1024.\n",
    "\n",
    "The number 500 in the fully connected layer is the number of neurons (or nodes) in that layer. This is a hyperparameter that you can adjust. Like other hyperparameters, the best value may depend on your specific data set and may require a bit of experimentation to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea9e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        # First conv layer: input channels = 3 (RGB), output channels = 32\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # Second conv layer: input channels = 32 (from previous layer), output channels = 64\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # Third conv layer: input channels = 64 (from previous layer), output channels = 128\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        # Fourth conv layer: input channels = 128 (from previous layer), output channels = 256\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Max pooling layer with kernel size 2 and stride 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        # First FC layer, input size should match the output size of the last conv layer\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 500)  # Adjusting to correct size after applying conv and pooling layers\n",
    "        # Second FC layer, output size is the same as the number of classes\n",
    "        self.fc2 = nn.Linear(500, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first conv layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Apply second conv layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Apply third conv layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # Apply fourth conv layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        # Flatten the tensor output from the conv layers\n",
    "        x = x.view(-1, 256 * 2 * 2)  # Adjusting to correct size after applying conv and pooling layers\n",
    "        # Apply first FC layer with ReLU after applying dropout\n",
    "        x = F.relu(self.fc1(self.dropout(x)))\n",
    "        # Apply second FC layer after applying dropout\n",
    "        x = self.fc2(self.dropout(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ab1b1",
   "metadata": {},
   "source": [
    "# Stage 3: Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d136e24",
   "metadata": {},
   "source": [
    "For this, we need to define a loss function and an optimiser. We will use Cross Entropy as our loss function, as it is a good choice for classification problems. For the optimiser, we will use Adam.\n",
    "\n",
    "Furthermore, we will divide our dataset into a training set and a validation set. During each epoch, we will train the model on the training set and then evaluate it on the validation set. If the performance on the validation set improves, we will save the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ef7c0",
   "metadata": {},
   "source": [
    "At the beginning i used lr = 0.01 and dropdown 0.5, but thesystem couldnt learn, with the the actual system, using lr= 0.001 and dropdown = 0.2 and 42 epochs, improving for 5.7... to 2.622346130905637 and still getting better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e16073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is using: cuda\n",
      "Previous mode was loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 782/782 [00:20<00:00, 37.62it/s, training_loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation Loss: 2.1465451087161993\n",
      "El loss actual es 337.0075820684433 y el mejor es 328.06292843818665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 782/782 [00:20<00:00, 37.80it/s, training_loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation Loss: 2.064161249027131\n",
      "El loss actual es 324.0733160972595 y el mejor es 328.06292843818665\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 782/782 [00:20<00:00, 37.61it/s, training_loss=2.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation Loss: 2.103996709653526\n",
      "El loss actual es 330.32748341560364 y el mejor es 324.0733160972595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 782/782 [00:20<00:00, 37.66it/s, training_loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation Loss: 2.0734938223650503\n",
      "El loss actual es 325.53853011131287 y el mejor es 324.0733160972595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 782/782 [00:20<00:00, 37.45it/s, training_loss=2.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation Loss: 2.0804724807192567\n",
      "El loss actual es 326.6341794729233 y el mejor es 324.0733160972595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 782/782 [00:20<00:00, 37.73it/s, training_loss=2.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation Loss: 2.082107401957178\n",
      "El loss actual es 326.8908621072769 y el mejor es 324.0733160972595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 782/782 [00:20<00:00, 37.38it/s, training_loss=3.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation Loss: 2.084197641937596\n",
      "El loss actual es 327.2190297842026 y el mejor es 324.0733160972595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 782/782 [00:20<00:00, 37.78it/s, training_loss=2.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation Loss: 2.0532965686670535\n",
      "El loss actual es 322.3675612807274 y el mejor es 324.0733160972595\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 782/782 [00:20<00:00, 37.69it/s, training_loss=2.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation Loss: 2.066421060805108\n",
      "El loss actual es 324.428106546402 y el mejor es 322.3675612807274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 782/782 [00:20<00:00, 38.03it/s, training_loss=2.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Loss: 2.0483098910872344\n",
      "El loss actual es 321.5846529006958 y el mejor es 322.3675612807274\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 782/782 [00:20<00:00, 37.74it/s, training_loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Validation Loss: 2.08134433494252\n",
      "El loss actual es 326.77106058597565 y el mejor es 321.5846529006958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 782/782 [00:20<00:00, 37.91it/s, training_loss=2.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Validation Loss: 2.0972976487153656\n",
      "El loss actual es 329.2757308483124 y el mejor es 321.5846529006958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 782/782 [00:20<00:00, 37.96it/s, training_loss=2.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Validation Loss: 2.0799420798660084\n",
      "El loss actual es 326.5509065389633 y el mejor es 321.5846529006958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 782/782 [00:20<00:00, 37.75it/s, training_loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Validation Loss: 2.0560935917933274\n",
      "El loss actual es 322.80669391155243 y el mejor es 321.5846529006958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 782/782 [00:20<00:00, 37.93it/s, training_loss=2.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Validation Loss: 2.0423939395102724\n",
      "El loss actual es 320.6558485031128 y el mejor es 321.5846529006958\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 782/782 [00:20<00:00, 37.90it/s, training_loss=2.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Validation Loss: 2.043713715425722\n",
      "El loss actual es 320.8630533218384 y el mejor es 320.6558485031128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 782/782 [00:20<00:00, 37.93it/s, training_loss=1.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Validation Loss: 2.0592130187210764\n",
      "El loss actual es 323.296443939209 y el mejor es 320.6558485031128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 782/782 [00:20<00:00, 38.04it/s, training_loss=2.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Validation Loss: 2.0288262314097896\n",
      "El loss actual es 318.525718331337 y el mejor es 320.6558485031128\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 782/782 [00:20<00:00, 37.70it/s, training_loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Validation Loss: 2.0270740234168474\n",
      "El loss actual es 318.250621676445 y el mejor es 318.525718331337\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 782/782 [00:20<00:00, 37.91it/s, training_loss=2.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Validation Loss: 2.012623010926945\n",
      "El loss actual es 315.9818127155304 y el mejor es 318.250621676445\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 782/782 [00:20<00:00, 37.92it/s, training_loss=2.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Validation Loss: 2.0057602270393615\n",
      "El loss actual es 314.90435564517975 y el mejor es 315.9818127155304\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 782/782 [00:20<00:00, 37.82it/s, training_loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Validation Loss: 2.038025811219671\n",
      "El loss actual es 319.97005236148834 y el mejor es 314.90435564517975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 782/782 [00:20<00:00, 37.89it/s, training_loss=2.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Validation Loss: 2.034542419348553\n",
      "El loss actual es 319.4231598377228 y el mejor es 314.90435564517975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 782/782 [00:20<00:00, 37.85it/s, training_loss=2.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Validation Loss: 2.0214989390342857\n",
      "El loss actual es 317.3753334283829 y el mejor es 314.90435564517975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 782/782 [00:20<00:00, 37.62it/s, training_loss=2.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Validation Loss: 2.0451411418854053\n",
      "El loss actual es 321.0871592760086 y el mejor es 314.90435564517975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 782/782 [00:20<00:00, 37.95it/s, training_loss=2.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Validation Loss: 2.026742973145406\n",
      "El loss actual es 318.19864678382874 y el mejor es 314.90435564517975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 782/782 [00:20<00:00, 38.00it/s, training_loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Validation Loss: 2.0242792519794146\n",
      "El loss actual es 317.8118425607681 y el mejor es 314.90435564517975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 782/782 [00:20<00:00, 37.95it/s, training_loss=2.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Validation Loss: 2.0247961206800618\n",
      "El loss actual es 317.8929909467697 y el mejor es 314.90435564517975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 782/782 [00:20<00:00, 37.98it/s, training_loss=2.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Validation Loss: 2.0043560638549223\n",
      "El loss actual es 314.6839020252228 y el mejor es 314.90435564517975\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 782/782 [00:20<00:00, 37.84it/s, training_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Validation Loss: 2.0056994599141893\n",
      "El loss actual es 314.8948152065277 y el mejor es 314.6839020252228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 782/782 [00:20<00:00, 37.59it/s, training_loss=2.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Validation Loss: 2.0435673279367434\n",
      "El loss actual es 320.8400704860687 y el mejor es 314.6839020252228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 782/782 [00:20<00:00, 37.65it/s, training_loss=2.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Validation Loss: 2.00271067877484\n",
      "El loss actual es 314.42557656764984 y el mejor es 314.6839020252228\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 782/782 [00:20<00:00, 37.89it/s, training_loss=1.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Validation Loss: 2.003272684516421\n",
      "El loss actual es 314.51381146907806 y el mejor es 314.42557656764984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 782/782 [00:20<00:00, 37.83it/s, training_loss=1.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Validation Loss: 2.012114076857354\n",
      "El loss actual es 315.9019100666046 y el mejor es 314.42557656764984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 782/782 [00:20<00:00, 37.66it/s, training_loss=2.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Validation Loss: 2.0733618895719004\n",
      "El loss actual es 325.5178166627884 y el mejor es 314.42557656764984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 782/782 [00:20<00:00, 37.74it/s, training_loss=1.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Validation Loss: 2.076201391827529\n",
      "El loss actual es 325.963618516922 y el mejor es 314.42557656764984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 782/782 [00:20<00:00, 37.73it/s, training_loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Validation Loss: 2.013128548670726\n",
      "El loss actual es 316.061182141304 y el mejor es 314.42557656764984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 782/782 [00:20<00:00, 37.75it/s, training_loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Validation Loss: 2.0275625225844656\n",
      "El loss actual es 318.3273160457611 y el mejor es 314.42557656764984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 782/782 [00:20<00:00, 37.84it/s, training_loss=3.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Validation Loss: 2.010284066959551\n",
      "El loss actual es 315.61459851264954 y el mejor es 314.42557656764984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 782/782 [00:20<00:00, 37.72it/s, training_loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Validation Loss: 1.986903890302986\n",
      "El loss actual es 311.9439107775688 y el mejor es 314.42557656764984\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 782/782 [00:20<00:00, 37.83it/s, training_loss=2.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Validation Loss: 2.0042446062063717\n",
      "El loss actual es 314.66640317440033 y el mejor es 311.9439107775688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 782/782 [00:20<00:00, 37.68it/s, training_loss=3.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Validation Loss: 2.0007071426719616\n",
      "El loss actual es 314.111021399498 y el mejor es 311.9439107775688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 782/782 [00:20<00:00, 37.60it/s, training_loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Validation Loss: 2.0266484978852\n",
      "El loss actual es 318.1838141679764 y el mejor es 311.9439107775688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 782/782 [00:20<00:00, 37.87it/s, training_loss=1.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Validation Loss: 1.9757840694135922\n",
      "El loss actual es 310.19809889793396 y el mejor es 311.9439107775688\n",
      "model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 782/782 [00:20<00:00, 37.69it/s, training_loss=2.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Validation Loss: 2.069146333986027\n",
      "El loss actual es 324.8559744358063 y el mejor es 310.19809889793396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 782/782 [00:20<00:00, 37.81it/s, training_loss=1.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Validation Loss: 2.0041393618674794\n",
      "El loss actual es 314.6498798131943 y el mejor es 310.19809889793396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 782/782 [00:20<00:00, 37.77it/s, training_loss=2.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Validation Loss: 2.0263700986364084\n",
      "El loss actual es 318.14010548591614 y el mejor es 310.19809889793396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 782/782 [00:20<00:00, 37.74it/s, training_loss=2.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Validation Loss: 2.0104943027921545\n",
      "El loss actual es 315.6476055383682 y el mejor es 310.19809889793396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 782/782 [00:20<00:00, 37.89it/s, training_loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Validation Loss: 2.013842440714502\n",
      "El loss actual es 316.1732631921768 y el mejor es 310.19809889793396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 782/782 [00:20<00:00, 38.06it/s, training_loss=2.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Validation Loss: 2.006838565419434\n",
      "El loss actual es 315.07365477085114 y el mejor es 310.19809889793396\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Try to use cuda if posible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"It is using: \" + device.type)\n",
    "\n",
    "# Initialice the network\n",
    "model = Net().to(device)\n",
    "\n",
    "# Path to save the model\n",
    "model_path = 'best_model_v2.pth'\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Previous mode was loaded.\")\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "else:\n",
    "    print(\"Not previous model found.\")\n",
    "    model = Net().to(device)\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 regularization\n",
    "\n",
    "# Define a number of training epochs\n",
    "epochs = 50\n",
    "\n",
    "#actually is my best\n",
    "best_loss = 50\n",
    "\n",
    "best_val_loss = 310.19809889793396  # Initialize with a high value\n",
    "\n",
    "# Training loop\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming that we have 100 classes for the CIFAR-100 dataset\n",
    "class_names = [f'class_{i}' for i in range(100)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Create a progress bar\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "    \n",
    "    for inputs, labels in progress_bar:\n",
    "        # Move data to the GPU if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the progress bar\n",
    "        progress_bar.set_postfix({'training_loss': loss.item()})\n",
    "\n",
    "    # Initialize lists to store predictions and labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Move data to the GPU if available\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update the validation loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate and print accuracy, recall, and F1-score\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    # Calculate and print confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel(\"Real value\")\n",
    "    plt.xlabel(\"Predicted value\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print epoch loss\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss/len(test_loader)}')\n",
    "\n",
    "    # Save the model if it has the best validation loss so far\n",
    "    print(f'El loss actual es {val_loss} y el mejor es {best_val_loss}')\n",
    "    if val_loss < best_val_loss:\n",
    "        print(\"model saved\")\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_v2.pth')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d483f",
   "metadata": {},
   "source": [
    "# Stage 4 my own tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31550b95",
   "metadata": {},
   "source": [
    "As you can see below, the neuronal network still neading more epochs for improve its results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1efe074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is using: cuda\n",
      "Predicted: ['lobster', 'train', 'table', 'kangaroo', 'tractor', 'orchid', 'rose', 'orange', 'can', 'tulip', 'wardrobe', 'ray', 'butterfly', 'cockroach', 'pine_tree', 'cattle', 'caterpillar', 'train', 'man', 'beaver', 'cloud', 'tulip', 'lawn_mower', 'tiger', 'chimpanzee', 'sunflower', 'elephant', 'dinosaur', 'snake', 'wolf', 'bottle', 'worm', 'lizard', 'palm_tree', 'lizard', 'raccoon', 'poppy', 'sea', 'rose', 'couch', 'tractor', 'castle', 'television', 'elephant', 'sunflower', 'wardrobe', 'beetle', 'sunflower', 'bus', 'rocket', 'wolf', 'poppy', 'skunk', 'turtle', 'tiger', 'dolphin', 'road', 'trout', 'willow_tree', 'woman', 'poppy', 'boy', 'bottle', 'skyscraper']\n",
      "True:      ['lobster', 'streetcar', 'table', 'raccoon', 'tractor', 'orchid', 'rose', 'sweet_pepper', 'lamp', 'tulip', 'wardrobe', 'ray', 'beetle', 'cockroach', 'mouse', 'elephant', 'caterpillar', 'bus', 'baby', 'snake', 'cloud', 'tulip', 'lawn_mower', 'lion', 'tiger', 'bee', 'elephant', 'dinosaur', 'beetle', 'leopard', 'bottle', 'plate', 'rabbit', 'sea', 'otter', 'plate', 'aquarium_fish', 'sea', 'tulip', 'couch', 'flatfish', 'elephant', 'television', 'elephant', 'maple_tree', 'wardrobe', 'beetle', 'sunflower', 'bee', 'skyscraper', 'wolf', 'man', 'skunk', 'leopard', 'fox', 'dolphin', 'road', 'trout', 'willow_tree', 'chimpanzee', 'poppy', 'boy', 'lamp', 'skyscraper']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Load the saved model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"It is using: \" + device.type)\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('best_model_v2.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get a batch of validation data\n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "# The outputs are probabilities for each class. To get the predicted class, we take the index of the highest probability.\n",
    "_, preds = torch.max(probabilities, 1)\n",
    "\n",
    "# Cargando las etiquetas de CIFAR-100\n",
    "with open('./dataset/train/cifar-100-python/meta', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "    fine_label_names = [t.decode('utf8') for t in data[b'fine_label_names']]\n",
    "\n",
    "# Utilizando las etiquetas para imprimir las clases predichas\n",
    "print('Predicted:', [fine_label_names[i] for i in preds])\n",
    "print('True:     ', [fine_label_names[i] for i in labels])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
