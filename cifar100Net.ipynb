{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c98ee40",
   "metadata": {},
   "source": [
    "## CIFAR 100 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79f88b",
   "metadata": {},
   "source": [
    "# Stage 1: Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0012c6",
   "metadata": {},
   "source": [
    "In this case we are going to develop a cifar 100 classification problem, for that we a re going to use the cifar100 dataset availablwe in torchvision, Although we are going to apply data augmentation for make the neuronal network more robust, and batch size of 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79018184",
   "metadata": {},
   "source": [
    "For this time i will use 256x256 size images, letting to the neuronal network learn better, so i have made some changes in stage 2. May be this is not the most efficient resize because cifar 100 are only 32x32 pixel on each image, so it will not give more information, but i want to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, ConcatDataset, DataLoader\n",
    "\n",
    "#Augmentation data for being morerobust\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "    transforms.RandomResizedCrop(256),\n",
    "    transforms.ToTensor(),  # Converts the image into a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((256,256)),  # Resizes the image to 64x64\n",
    "    transforms.ToTensor(),  # Converts the image into a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizes the tensors (mean and std deviation for 3 color channels)\n",
    "])\n",
    "\n",
    "# Create Train dataset\n",
    "train_dataset = datasets.CIFAR100(root = './dataset/train',download=True, train=True, transform=transform_train)\n",
    "# Create Test dataset\n",
    "test_dataset = datasets.CIFAR100(root = './dataset/test',download=True, train=False, transform=transform_test) \n",
    "\n",
    "#Create train loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "#Create test loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34ae2f",
   "metadata": {},
   "source": [
    "# Stage 2: building neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8a8b6",
   "metadata": {},
   "source": [
    "Stride: The stride refers to how many pixels the filter moves through the image or input volume at each step during the convolution operation. A stride of 1 means that the filter moves one pixel at a time. A stride of 2 means that the filter moves two pixels at a time, and so on. A larger stride will result in a lower spatial dimension output.\n",
    "\n",
    "Padding: Padding refers to the addition of extra pixels around the input image or volume before applying the convolution operation. The purpose of padding is to control the spatial dimension of the output. It is especially useful when you want to keep the spatial dimensions of the input and output the same after the convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8baf2e",
   "metadata": {},
   "source": [
    "For this time i will use 4 convolutional layer, letting to the network learn more complex forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # First convolutional layer: input channels = 3 (RGB), output channels = 32\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # Second convolutional layer: input channels = 32 (from previous layer), output channels = 64\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # Third convolutional layer: input channels = 64 (from previous layer), output channels = 128\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        # Fourth convolutional layer: input channels = 128 (from previous layer), output channels = 256\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # First fully connected layer, input size should match the output size of the last conv layer\n",
    "        self.fc1 = nn.Linear(256 * 16 * 16, 500)\n",
    "        # Second fully connected layer, output size is the same as the number of classes\n",
    "        self.fc2 = nn.Linear(500, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first conv layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Apply second conv layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Apply third conv layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # Apply fourth conv layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        # Flatten the tensor output from the conv layers\n",
    "        x = x.view(-1, 256 * 16 * 16)\n",
    "        # Apply first fully connected layer with ReLU after applying dropout\n",
    "        x = F.relu(self.fc1(self.dropout(x)))\n",
    "        # Apply second fully connected layer after applying dropout\n",
    "        x = self.fc2(self.dropout(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ab1b1",
   "metadata": {},
   "source": [
    "# Stage 3: Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d136e24",
   "metadata": {},
   "source": [
    "For this, we need to define a loss function and an optimiser. We will use Cross Entropy as our loss function, as it is a good choice for classification problems. For the optimiser, we will use Adam.\n",
    "\n",
    "Furthermore, we will divide our dataset into a training set and a validation set. During each epoch, we will train the model on the training set and then evaluate it on the validation set. If the performance on the validation set improves, we will save the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ef7c0",
   "metadata": {},
   "source": [
    "At the beginning i used lr = 0.01 and dropdown 0.5, but thesystem couldnt learn, with the the actual system, using lr= 0.001 and dropdown = 0.2 and 42 epochs, improving for 5.7... to 2.622346130905637 and still getting better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e16073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Try to use cuda if posible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"It is using: \" + device.type)\n",
    "\n",
    "# Initialice the network\n",
    "model = Net().to(device)\n",
    "\n",
    "# Path to save the model\n",
    "model_path = 'best_model.pth'\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Previous mode was loaded.\")\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "else:\n",
    "    print(\"Not previous model found.\")\n",
    "    model = Net().to(device)\n",
    "    \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 regularization\n",
    "\n",
    "# Define a number of training epochs\n",
    "epochs = 30\n",
    "\n",
    "#actually is my best\n",
    "best_loss = 50\n",
    "\n",
    "best_val_loss = 368.8841189146042  # Initialize with a high value\n",
    "\n",
    "# Training loop\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming that we have 100 classes for the CIFAR-100 dataset\n",
    "class_names = [f'class_{i}' for i in range(100)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Create a progress bar\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "    \n",
    "    for inputs, labels in progress_bar:\n",
    "        # Move data to the GPU if available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the progress bar\n",
    "        progress_bar.set_postfix({'training_loss': loss.item()})\n",
    "\n",
    "    # Initialize lists to store predictions and labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Move data to the GPU if available\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update the validation loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate and print accuracy, recall, and F1-score\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    # Calculate and print confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel(\"Real value\")\n",
    "    plt.xlabel(\"Predicted value\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print epoch loss\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss/len(test_loader)}')\n",
    "\n",
    "    # Save the model if it has the best validation loss so far\n",
    "    print(f'El loss actual es {val_loss} y el mejor es {best_val_loss}')\n",
    "    if val_loss < best_val_loss:\n",
    "        print(\"model saved\")\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d483f",
   "metadata": {},
   "source": [
    "# Stage 4 my own tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31550b95",
   "metadata": {},
   "source": [
    "As you can see below, the neuronal network still neading more epochs for improve its results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1efe074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is using: cuda\n",
      "Predicted: ['maple_tree', 'dolphin', 'whale', 'sea', 'lamp', 'girl', 'crocodile', 'otter', 'flatfish', 'bicycle', 'boy', 'table', 'plate', 'tractor', 'baby', 'streetcar', 'cockroach', 'motorcycle', 'dolphin', 'rabbit', 'pickup_truck', 'house', 'telephone', 'spider', 'baby', 'snail', 'cup', 'oak_tree', 'porcupine', 'cup', 'seal', 'possum', 'shark', 'cup', 'raccoon', 'shark', 'tiger', 'crocodile', 'crocodile', 'can', 'skunk', 'road', 'lobster', 'willow_tree', 'man', 'chair', 'woman', 'oak_tree', 'otter', 'pickup_truck', 'cattle', 'porcupine', 'wardrobe', 'lobster', 'chair', 'road', 'rabbit', 'whale', 'rose', 'house', 'mushroom', 'squirrel', 'leopard', 'butterfly']\n",
      "True:      ['maple_tree', 'dolphin', 'whale', 'dolphin', 'lamp', 'girl', 'otter', 'mouse', 'whale', 'bicycle', 'flatfish', 'table', 'plate', 'pine_tree', 'hamster', 'whale', 'cockroach', 'motorcycle', 'shark', 'wolf', 'train', 'bus', 'television', 'spider', 'baby', 'crab', 'dinosaur', 'oak_tree', 'hamster', 'cup', 'dinosaur', 'spider', 'ray', 'cup', 'snake', 'cattle', 'hamster', 'whale', 'ray', 'can', 'skunk', 'road', 'aquarium_fish', 'willow_tree', 'girl', 'bed', 'bicycle', 'willow_tree', 'rocket', 'bus', 'wardrobe', 'mouse', 'can', 'clock', 'chair', 'beetle', 'telephone', 'whale', 'tulip', 'bicycle', 'lamp', 'turtle', 'leopard', 'bear']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Load the saved model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"It is using: \" + device.type)\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get a batch of validation data\n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "# The outputs are probabilities for each class. To get the predicted class, we take the index of the highest probability.\n",
    "_, preds = torch.max(probabilities, 1)\n",
    "\n",
    "# Cargando las etiquetas de CIFAR-100\n",
    "with open('./dataset/train/cifar-100-python/meta', 'rb') as file:\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "    fine_label_names = [t.decode('utf8') for t in data[b'fine_label_names']]\n",
    "\n",
    "# Utilizando las etiquetas para imprimir las clases predichas\n",
    "print('Predicted:', [fine_label_names[i] for i in preds])\n",
    "print('True:     ', [fine_label_names[i] for i in labels])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
